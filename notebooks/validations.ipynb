{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Abysima: Language Generation Experiments\n",
    "\n",
    "The following notebook will experiment with generating a language using neural networks and generative deep learning.\n",
    "This is, by no means, a production-ready system, nor is it a complete network; rather, the purpose of this experiment\n",
    "is to see what is possible with creating a language.\n",
    "\n",
    "For more information on the process and supporting research, please refer to the Linguistics Paper document found in the\n",
    "`01 - Areas of Responsibility` directory.\n",
    "\n",
    "The following source code and datasets are licensed under the Mozilla Public License v2.0. Please refer to the LICENSE\n",
    "file that came with this repository for more information on what your rights are with usage and modification of this\n",
    "software. If a LICENSE file is not provided, you can obtain a copy at https://www.mozilla.org/en-US/MPL/2.0/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Collecting the Dataset\n",
    "\n",
    "Before we can create networks that will be able to train off of words, sniglets, and non-words, we first need to create\n",
    "a dataset that the networking models will be able to understand.\n",
    "\n",
    "To do this, we will create two pools of data: a list full of valid words, and a list of random strings, both of equal\n",
    "count. The list of valid words derives from the words found in the `/usr/share/dict/words` file found on UNIX and Linux\n",
    "systems, which contains words of various languages. A list of basic Japanese words written in Romaji are also included\n",
    "in the list.\n",
    "\n",
    "Words in the valid pool are then trimmed based on the average length of the words in that dataset, removing any words\n",
    "that are bigger than the specified length. This is crucial because this will help prevent miscalculations due to a lot\n",
    "of whitespace. Additionally, words that are acronyms, contractions, and/or less than three characters long are removed\n",
    "from the list. The invalid word dataset is generated from an algorithm that randomly selects letters from three to the\n",
    "average length.\n",
    "\n",
    "Neural networks need each entry in the dataset to be of the same length, since they are fundamentally rows in a large\n",
    "matrix. To accomplish this, we will append asterisks (`'*'`) at the end of words when needed; this is known as _padding_\n",
    "_a sequence_.\n",
    "\n",
    "We also need to be able to indicate which words are valid and which ones were randomly generated. To do this, we will\n",
    "add an extra column to the dataset that will indicate its validity by writing either \"valid\" or \"invalid\".\n",
    "\n",
    "The dataset is then shuffled between twenty-five to fifty times to make sure that we aren't only training on valid words\n",
    "or vice-versa. Once this shuffling is complete, we will split the dataset into two pools, where eighty percent (80%) of\n",
    "the data will go into a training pool, and twenty percent (20%) will go into a testing pool. The training pool will be\n",
    "used to train the network, and the testing pool will be used to test that the trained network is making as close to an\n",
    "accurate prediction as possible.\n",
    "\n",
    "We then take these two pools and write them to CSV files which all of our models will be able to read. The script that\n",
    "implements this process is available in `create_dataset.py` in the project's root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char01</th>\n",
       "      <th>char02</th>\n",
       "      <th>char03</th>\n",
       "      <th>char04</th>\n",
       "      <th>char05</th>\n",
       "      <th>char06</th>\n",
       "      <th>char07</th>\n",
       "      <th>char08</th>\n",
       "      <th>Valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>v</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>*</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>r</td>\n",
       "      <td>u</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>y</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  char01 char02 char03 char04 char05 char06 char07 char08    Valid\n",
       "0      v      f      t      *      *      *      *      *  invalid\n",
       "1      f      y      u      t      *      *      *      *  invalid\n",
       "2      g      l      e      a      n      i      n      g    valid\n",
       "3      a      l      l      o      v      e      r      *    valid\n",
       "4      c      r      u      s      t      y      *      *    valid"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Pandas library, which will read the CSV files that we wrote.\n",
    "import pandas as pd\n",
    "\n",
    "# Import the training and testing pools.\n",
    "DF_TRAINING_POOL = pd.read_csv(\"../datasets/dtrain.csv\")\n",
    "DF_TESTING_POOL = pd.read_csv(\"../datasets/dtest.csv\")\n",
    "\n",
    "# Make a preview of the data frame from the training pool. Note that our features are the eight characters, and the\n",
    "# target is the 'Valid' column.\n",
    "DF_TRAINING_POOL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (79572, 9)\n",
      "Test shape: (19894, 9)\n",
      "Total rows: 99466\n"
     ]
    }
   ],
   "source": [
    "# Neural networks will need to encode the data in order to be able to train. We will write an encoder and apply it to\n",
    "# the dataset here.\n",
    "from string import ascii_lowercase\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def encode_features(feature) -> float:\n",
    "    \"\"\"Returns an encoded number that represents the data item.\"\"\"\n",
    "    if feature == '*' or feature == 'invalid':\n",
    "        return 0.0\n",
    "    elif feature == 'valid':\n",
    "        return 1.0\n",
    "    else:\n",
    "        return (ascii_lowercase.index(feature) + 1) / 26.0\n",
    "\n",
    "\n",
    "# Convert the data frames into NumPy arrays, which will be used in the neural networks.\n",
    "DATA_TRAIN = DF_TRAINING_POOL.to_numpy()\n",
    "DATA_TEST = DF_TESTING_POOL.to_numpy()\n",
    "\n",
    "# Make the mapping function that will convert the strings in the datasets into numbers with the function we defined\n",
    "# earlier and map them on our datasets.\n",
    "map_func = np.vectorize(encode_features)\n",
    "DATA_TRAIN = map_func(DATA_TRAIN)\n",
    "DATA_TEST = map_func(DATA_TEST)\n",
    "\n",
    "DATASET_COUNT = DATA_TRAIN.shape[0] + DATA_TEST.shape[0]  # type: ignore\n",
    "\n",
    "# Print out the sizes of the training and testing datasets.\n",
    "print(f\"Train shape: {DATA_TRAIN.shape}\")  # type: ignore\n",
    "print(f\"Test shape: {DATA_TEST.shape}\")  # type: ignore\n",
    "print(f\"Total rows: {DATASET_COUNT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84615385 0.23076923 0.76923077 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.23076923 0.96153846 0.80769231 0.76923077 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.26923077 0.46153846 0.19230769 0.03846154 0.53846154 0.34615385\n",
      "  0.53846154 0.26923077]\n",
      " [0.03846154 0.46153846 0.46153846 0.57692308 0.84615385 0.19230769\n",
      "  0.69230769 0.        ]\n",
      " [0.11538462 0.69230769 0.80769231 0.73076923 0.76923077 0.96153846\n",
      "  0.         0.        ]]\n",
      "[0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Split the training and testing datasets into X and Y components. X will contain all of the features, and Y will\n",
    "# contain the target value.\n",
    "X_train, y_train = DATA_TRAIN[:, :-1], DATA_TRAIN[:, -1]  # type: ignore\n",
    "X_test, y_test = DATA_TEST[:, :-1], DATA_TEST[:, -1]  # type: ignore\n",
    "\n",
    "print(X_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Creating our Networks\n",
    "\n",
    "Now that we have our dataset ready, we will begin creating neural networks that will train on the data we specify.\n",
    "These neural networks operate similar to our own brains and will try to \"learn\" what makes a word valid by using\n",
    "mathematical equations running in the background.\n",
    "\n",
    "To accomplish this, we will utilize two frameworks that exist: Tensorflow and CoreML. Tensorflow is a library created\n",
    "by Google to make neural networks from scratch without writing all of the code to process the math. Likewise, CoreML\n",
    "is a library made by Apple that lets developers create neural networks for use in apps on their platforms (macOS, iOS,\n",
    "tvOS, and watchOS).\n",
    "\n",
    "For this experiment, we will design three networks:\n",
    "\n",
    "- First, a fully-connected neural network (FCNN). This type of network indicates that all of the nodes in the network\n",
    "  link up to each other in some way. This is the most \"basic\" neural network in the list.\n",
    "- Next, a recurrent neural network (RNN) using the Long Short-Term Memory strategy (LSTM). Recurrent neural networks\n",
    "  operate very similarly to FCNNs in that nodes are connected. However, it recognizes that the data it receives is\n",
    "  sequential, meaning that they appear in a sequence. The network will perform mathematical operations and learn with\n",
    "  this in mind.\n",
    "- Finally, a CoreML model created with Create ML. This dataset is pre-trained and automatically selected an algorithm\n",
    "  that it thinks works best for the dataset. Exact implementation is unknown since Apple hides this from the developer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will specify parameters here that will be used to train the networks we are creating. These parameters can be\n",
    "# adjusted by us at any time to optimize the algorithms. These parameters are known as 'hyperparameters'.\n",
    "\n",
    "# Specify the number of \"iterations\" the neural networks will run under. In this case, an iteration indicates a session\n",
    "# of training by reading the data and running operations on it.\n",
    "KERAS_EPOCHS = 500\n",
    "\n",
    "# Specify the number of batches the neural networks will use. To speed up training, our networks will run updates after\n",
    "# a certain number of batches, making updates as necessary.\n",
    "KERAS_BATCHES = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 393\n",
      "Trainable params: 393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import the Tensorflow and Keras libraries needed to make two of the networks.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create the FCNN. This will have a first layer that maps to the number of characters in our set: in this case, 8. We\n",
    "# also include some hidden layers of various lengths before including a final layer that will filter down to a single\n",
    "# input.\n",
    "FCNN = keras.Sequential()\n",
    "FCNN.add(Dense(8, input_dim=8, activation=\"relu\"))\n",
    "FCNN.add(Dense(32, activation='relu'))\n",
    "FCNN.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model and use 'binary cross-entropy' to foce the network to either say \"yes\" or \"no\". We will also use the\n",
    "# adam optimizer and list accuracy in our metrics for further analysis.\n",
    "FCNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print out a summary of the FCNN.\n",
    "FCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.6106 - val_loss: 0.6022 - val_accuracy: 0.6842\n",
      "Epoch 2/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.5664 - accuracy: 0.7092 - val_loss: 0.5500 - val_accuracy: 0.7108\n",
      "Epoch 3/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.5301 - accuracy: 0.7181 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 4/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.7353 - val_loss: 0.5041 - val_accuracy: 0.7407\n",
      "Epoch 5/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.7517 - val_loss: 0.4890 - val_accuracy: 0.7534\n",
      "Epoch 6/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.7601 - val_loss: 0.4805 - val_accuracy: 0.7577\n",
      "Epoch 7/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7612 - val_loss: 0.4776 - val_accuracy: 0.7570\n",
      "Epoch 8/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7614 - val_loss: 0.4761 - val_accuracy: 0.7583\n",
      "Epoch 9/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7622 - val_loss: 0.4726 - val_accuracy: 0.7585\n",
      "Epoch 10/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7627 - val_loss: 0.4716 - val_accuracy: 0.7590\n",
      "Epoch 11/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7624 - val_loss: 0.4713 - val_accuracy: 0.7595\n",
      "Epoch 12/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7631 - val_loss: 0.4701 - val_accuracy: 0.7595\n",
      "Epoch 13/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7630 - val_loss: 0.4700 - val_accuracy: 0.7590\n",
      "Epoch 14/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7641 - val_loss: 0.4686 - val_accuracy: 0.7596\n",
      "Epoch 15/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4664 - accuracy: 0.7638 - val_loss: 0.4698 - val_accuracy: 0.7609\n",
      "Epoch 16/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7632 - val_loss: 0.4678 - val_accuracy: 0.7609\n",
      "Epoch 17/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7639 - val_loss: 0.4668 - val_accuracy: 0.7610\n",
      "Epoch 18/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7650 - val_loss: 0.4666 - val_accuracy: 0.7614\n",
      "Epoch 19/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7651 - val_loss: 0.4663 - val_accuracy: 0.7634\n",
      "Epoch 20/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4637 - accuracy: 0.7652 - val_loss: 0.4664 - val_accuracy: 0.7629\n",
      "Epoch 21/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7665 - val_loss: 0.4672 - val_accuracy: 0.7641\n",
      "Epoch 22/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7664 - val_loss: 0.4674 - val_accuracy: 0.7610\n",
      "Epoch 23/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.7665 - val_loss: 0.4638 - val_accuracy: 0.7651\n",
      "Epoch 24/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7681 - val_loss: 0.4635 - val_accuracy: 0.7658\n",
      "Epoch 25/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7685 - val_loss: 0.4635 - val_accuracy: 0.7661\n",
      "Epoch 26/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4607 - accuracy: 0.7695 - val_loss: 0.4622 - val_accuracy: 0.7659\n",
      "Epoch 27/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.7697 - val_loss: 0.4618 - val_accuracy: 0.7682\n",
      "Epoch 28/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.7707 - val_loss: 0.4624 - val_accuracy: 0.7673\n",
      "Epoch 29/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7705 - val_loss: 0.4620 - val_accuracy: 0.7658\n",
      "Epoch 30/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.7717 - val_loss: 0.4598 - val_accuracy: 0.7681\n",
      "Epoch 31/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4578 - accuracy: 0.7726 - val_loss: 0.4591 - val_accuracy: 0.7689\n",
      "Epoch 32/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.7725 - val_loss: 0.4593 - val_accuracy: 0.7707\n",
      "Epoch 33/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4568 - accuracy: 0.7724 - val_loss: 0.4582 - val_accuracy: 0.7690\n",
      "Epoch 34/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4561 - accuracy: 0.7736 - val_loss: 0.4577 - val_accuracy: 0.7702\n",
      "Epoch 35/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4549 - accuracy: 0.7747 - val_loss: 0.4571 - val_accuracy: 0.7705\n",
      "Epoch 36/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4540 - accuracy: 0.7753 - val_loss: 0.4559 - val_accuracy: 0.7713\n",
      "Epoch 37/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4530 - accuracy: 0.7762 - val_loss: 0.4566 - val_accuracy: 0.7725\n",
      "Epoch 38/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4521 - accuracy: 0.7769 - val_loss: 0.4533 - val_accuracy: 0.7742\n",
      "Epoch 39/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.4531 - val_accuracy: 0.7731\n",
      "Epoch 40/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.7782 - val_loss: 0.4519 - val_accuracy: 0.7752\n",
      "Epoch 41/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4493 - accuracy: 0.7789 - val_loss: 0.4517 - val_accuracy: 0.7743\n",
      "Epoch 42/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4488 - accuracy: 0.7793 - val_loss: 0.4506 - val_accuracy: 0.7751\n",
      "Epoch 43/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4482 - accuracy: 0.7804 - val_loss: 0.4501 - val_accuracy: 0.7761\n",
      "Epoch 44/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.7796 - val_loss: 0.4500 - val_accuracy: 0.7763\n",
      "Epoch 45/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4471 - accuracy: 0.7800 - val_loss: 0.4494 - val_accuracy: 0.7770\n",
      "Epoch 46/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4464 - accuracy: 0.7806 - val_loss: 0.4492 - val_accuracy: 0.7757\n",
      "Epoch 47/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4465 - accuracy: 0.7803 - val_loss: 0.4489 - val_accuracy: 0.7767\n",
      "Epoch 48/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4460 - accuracy: 0.7805 - val_loss: 0.4484 - val_accuracy: 0.7771\n",
      "Epoch 49/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4454 - accuracy: 0.7802 - val_loss: 0.4490 - val_accuracy: 0.7759\n",
      "Epoch 50/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.7807 - val_loss: 0.4472 - val_accuracy: 0.7779\n",
      "Epoch 51/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4446 - accuracy: 0.7807 - val_loss: 0.4471 - val_accuracy: 0.7784\n",
      "Epoch 52/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.7811 - val_loss: 0.4479 - val_accuracy: 0.7776\n",
      "Epoch 53/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.4465 - val_accuracy: 0.7776\n",
      "Epoch 54/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.4457 - val_accuracy: 0.7772\n",
      "Epoch 55/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4434 - accuracy: 0.7818 - val_loss: 0.4451 - val_accuracy: 0.7786\n",
      "Epoch 56/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4425 - accuracy: 0.7822 - val_loss: 0.4466 - val_accuracy: 0.7774\n",
      "Epoch 57/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.7821 - val_loss: 0.4448 - val_accuracy: 0.7795\n",
      "Epoch 58/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.7818 - val_loss: 0.4442 - val_accuracy: 0.7808\n",
      "Epoch 59/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.7823 - val_loss: 0.4441 - val_accuracy: 0.7788\n",
      "Epoch 60/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4412 - accuracy: 0.7829 - val_loss: 0.4430 - val_accuracy: 0.7819\n",
      "Epoch 61/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.7832 - val_loss: 0.4431 - val_accuracy: 0.7823\n",
      "Epoch 62/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4405 - accuracy: 0.7824 - val_loss: 0.4429 - val_accuracy: 0.7811\n",
      "Epoch 63/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.7833 - val_loss: 0.4419 - val_accuracy: 0.7805\n",
      "Epoch 64/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4395 - accuracy: 0.7835 - val_loss: 0.4413 - val_accuracy: 0.7829\n",
      "Epoch 65/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4394 - accuracy: 0.7839 - val_loss: 0.4413 - val_accuracy: 0.7822\n",
      "Epoch 66/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4393 - accuracy: 0.7838 - val_loss: 0.4408 - val_accuracy: 0.7823\n",
      "Epoch 67/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.7832 - val_loss: 0.4423 - val_accuracy: 0.7811\n",
      "Epoch 68/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4385 - accuracy: 0.7837 - val_loss: 0.4411 - val_accuracy: 0.7807\n",
      "Epoch 69/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4385 - accuracy: 0.7846 - val_loss: 0.4409 - val_accuracy: 0.7825\n",
      "Epoch 70/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.7844 - val_loss: 0.4405 - val_accuracy: 0.7822\n",
      "Epoch 71/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.7837 - val_loss: 0.4405 - val_accuracy: 0.7827\n",
      "Epoch 72/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4377 - accuracy: 0.7849 - val_loss: 0.4404 - val_accuracy: 0.7813\n",
      "Epoch 73/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4374 - accuracy: 0.7851 - val_loss: 0.4397 - val_accuracy: 0.7823\n",
      "Epoch 74/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.4408 - val_accuracy: 0.7813\n",
      "Epoch 75/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4373 - accuracy: 0.7844 - val_loss: 0.4397 - val_accuracy: 0.7818\n",
      "Epoch 76/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.7849 - val_loss: 0.4388 - val_accuracy: 0.7825\n",
      "Epoch 77/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4367 - accuracy: 0.7857 - val_loss: 0.4403 - val_accuracy: 0.7823\n",
      "Epoch 78/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4362 - accuracy: 0.7853 - val_loss: 0.4396 - val_accuracy: 0.7827\n",
      "Epoch 79/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4365 - accuracy: 0.7858 - val_loss: 0.4388 - val_accuracy: 0.7832\n",
      "Epoch 80/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4357 - accuracy: 0.7857 - val_loss: 0.4381 - val_accuracy: 0.7829\n",
      "Epoch 81/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.7855 - val_loss: 0.4381 - val_accuracy: 0.7827\n",
      "Epoch 82/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.7861 - val_loss: 0.4375 - val_accuracy: 0.7821\n",
      "Epoch 83/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4352 - accuracy: 0.7860 - val_loss: 0.4384 - val_accuracy: 0.7837\n",
      "Epoch 84/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.7862 - val_loss: 0.4385 - val_accuracy: 0.7832\n",
      "Epoch 85/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.7873 - val_loss: 0.4377 - val_accuracy: 0.7837\n",
      "Epoch 86/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4348 - accuracy: 0.7868 - val_loss: 0.4369 - val_accuracy: 0.7843\n",
      "Epoch 87/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.7863 - val_loss: 0.4366 - val_accuracy: 0.7827\n",
      "Epoch 88/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4350 - accuracy: 0.7857 - val_loss: 0.4367 - val_accuracy: 0.7836\n",
      "Epoch 89/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.7858 - val_loss: 0.4373 - val_accuracy: 0.7846\n",
      "Epoch 90/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4342 - accuracy: 0.7870 - val_loss: 0.4368 - val_accuracy: 0.7837\n",
      "Epoch 91/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4341 - accuracy: 0.7871 - val_loss: 0.4359 - val_accuracy: 0.7850\n",
      "Epoch 92/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4335 - accuracy: 0.7875 - val_loss: 0.4363 - val_accuracy: 0.7836\n",
      "Epoch 93/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.7885 - val_loss: 0.4357 - val_accuracy: 0.7849\n",
      "Epoch 94/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.7880 - val_loss: 0.4355 - val_accuracy: 0.7847\n",
      "Epoch 95/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4329 - accuracy: 0.7878 - val_loss: 0.4399 - val_accuracy: 0.7806\n",
      "Epoch 96/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4332 - accuracy: 0.7881 - val_loss: 0.4359 - val_accuracy: 0.7831\n",
      "Epoch 97/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.7886 - val_loss: 0.4352 - val_accuracy: 0.7838\n",
      "Epoch 98/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.7890 - val_loss: 0.4357 - val_accuracy: 0.7829\n",
      "Epoch 99/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4328 - accuracy: 0.7880 - val_loss: 0.4356 - val_accuracy: 0.7847\n",
      "Epoch 100/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.7886 - val_loss: 0.4338 - val_accuracy: 0.7859\n",
      "Epoch 101/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4319 - accuracy: 0.7883 - val_loss: 0.4331 - val_accuracy: 0.7854\n",
      "Epoch 102/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4320 - accuracy: 0.7888 - val_loss: 0.4355 - val_accuracy: 0.7835\n",
      "Epoch 103/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4316 - accuracy: 0.7886 - val_loss: 0.4336 - val_accuracy: 0.7863\n",
      "Epoch 104/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4312 - accuracy: 0.7892 - val_loss: 0.4330 - val_accuracy: 0.7849\n",
      "Epoch 105/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4310 - accuracy: 0.7900 - val_loss: 0.4335 - val_accuracy: 0.7851\n",
      "Epoch 106/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.7893 - val_loss: 0.4334 - val_accuracy: 0.7845\n",
      "Epoch 107/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4307 - accuracy: 0.7894 - val_loss: 0.4331 - val_accuracy: 0.7862\n",
      "Epoch 108/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.7886 - val_loss: 0.4334 - val_accuracy: 0.7852\n",
      "Epoch 109/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4305 - accuracy: 0.7894 - val_loss: 0.4345 - val_accuracy: 0.7835\n",
      "Epoch 110/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4308 - accuracy: 0.7907 - val_loss: 0.4326 - val_accuracy: 0.7859\n",
      "Epoch 111/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.7903 - val_loss: 0.4325 - val_accuracy: 0.7853\n",
      "Epoch 112/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.7900 - val_loss: 0.4319 - val_accuracy: 0.7866\n",
      "Epoch 113/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.7899 - val_loss: 0.4317 - val_accuracy: 0.7867\n",
      "Epoch 114/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.7901 - val_loss: 0.4325 - val_accuracy: 0.7869\n",
      "Epoch 115/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.7900 - val_loss: 0.4321 - val_accuracy: 0.7870\n",
      "Epoch 116/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4295 - accuracy: 0.7906 - val_loss: 0.4320 - val_accuracy: 0.7884\n",
      "Epoch 117/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4297 - accuracy: 0.7904 - val_loss: 0.4323 - val_accuracy: 0.7875\n",
      "Epoch 118/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4296 - accuracy: 0.7900 - val_loss: 0.4322 - val_accuracy: 0.7873\n",
      "Epoch 119/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.7904 - val_loss: 0.4314 - val_accuracy: 0.7870\n",
      "Epoch 120/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4291 - accuracy: 0.7911 - val_loss: 0.4316 - val_accuracy: 0.7881\n",
      "Epoch 121/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4288 - accuracy: 0.7917 - val_loss: 0.4317 - val_accuracy: 0.7864\n",
      "Epoch 122/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4288 - accuracy: 0.7913 - val_loss: 0.4311 - val_accuracy: 0.7870\n",
      "Epoch 123/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.7914 - val_loss: 0.4313 - val_accuracy: 0.7864\n",
      "Epoch 124/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.7919 - val_loss: 0.4303 - val_accuracy: 0.7869\n",
      "Epoch 125/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.7918 - val_loss: 0.4320 - val_accuracy: 0.7869\n",
      "Epoch 126/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.7919 - val_loss: 0.4318 - val_accuracy: 0.7881\n",
      "Epoch 127/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4284 - accuracy: 0.7922 - val_loss: 0.4317 - val_accuracy: 0.7886\n",
      "Epoch 128/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.7926 - val_loss: 0.4309 - val_accuracy: 0.7855\n",
      "Epoch 129/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.7927 - val_loss: 0.4304 - val_accuracy: 0.7890\n",
      "Epoch 130/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4278 - accuracy: 0.7928 - val_loss: 0.4315 - val_accuracy: 0.7885\n",
      "Epoch 131/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.7922 - val_loss: 0.4309 - val_accuracy: 0.7871\n",
      "Epoch 132/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.7927 - val_loss: 0.4298 - val_accuracy: 0.7896\n",
      "Epoch 133/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.7932 - val_loss: 0.4293 - val_accuracy: 0.7904\n",
      "Epoch 134/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.7930 - val_loss: 0.4298 - val_accuracy: 0.7886\n",
      "Epoch 135/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4278 - accuracy: 0.7924 - val_loss: 0.4309 - val_accuracy: 0.7897\n",
      "Epoch 136/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.7925 - val_loss: 0.4294 - val_accuracy: 0.7889\n",
      "Epoch 137/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.7933 - val_loss: 0.4289 - val_accuracy: 0.7888\n",
      "Epoch 138/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.7929 - val_loss: 0.4306 - val_accuracy: 0.7899\n",
      "Epoch 139/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.7935 - val_loss: 0.4290 - val_accuracy: 0.7911\n",
      "Epoch 140/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.7927 - val_loss: 0.4316 - val_accuracy: 0.7878\n",
      "Epoch 141/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4273 - accuracy: 0.7933 - val_loss: 0.4292 - val_accuracy: 0.7894\n",
      "Epoch 142/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4270 - accuracy: 0.7938 - val_loss: 0.4284 - val_accuracy: 0.7907\n",
      "Epoch 143/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4267 - accuracy: 0.7932 - val_loss: 0.4291 - val_accuracy: 0.7908\n",
      "Epoch 144/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.4280 - val_accuracy: 0.7911\n",
      "Epoch 145/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4264 - accuracy: 0.7945 - val_loss: 0.4281 - val_accuracy: 0.7911\n",
      "Epoch 146/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.7947 - val_loss: 0.4277 - val_accuracy: 0.7900\n",
      "Epoch 147/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.7942 - val_loss: 0.4298 - val_accuracy: 0.7903\n",
      "Epoch 148/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.7937 - val_loss: 0.4278 - val_accuracy: 0.7926\n",
      "Epoch 149/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.7935 - val_loss: 0.4305 - val_accuracy: 0.7891\n",
      "Epoch 150/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.4276 - val_accuracy: 0.7930\n",
      "Epoch 151/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.7948 - val_loss: 0.4290 - val_accuracy: 0.7910\n",
      "Epoch 152/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.7945 - val_loss: 0.4271 - val_accuracy: 0.7917\n",
      "Epoch 153/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.7947 - val_loss: 0.4282 - val_accuracy: 0.7924\n",
      "Epoch 154/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.7950 - val_loss: 0.4306 - val_accuracy: 0.7911\n",
      "Epoch 155/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.7946 - val_loss: 0.4268 - val_accuracy: 0.7916\n",
      "Epoch 156/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.7954 - val_loss: 0.4264 - val_accuracy: 0.7918\n",
      "Epoch 157/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4253 - accuracy: 0.7949 - val_loss: 0.4271 - val_accuracy: 0.7917\n",
      "Epoch 158/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.7958 - val_loss: 0.4268 - val_accuracy: 0.7910\n",
      "Epoch 159/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.7958 - val_loss: 0.4269 - val_accuracy: 0.7916\n",
      "Epoch 160/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4244 - accuracy: 0.7954 - val_loss: 0.4265 - val_accuracy: 0.7926\n",
      "Epoch 161/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4241 - accuracy: 0.7954 - val_loss: 0.4256 - val_accuracy: 0.7925\n",
      "Epoch 162/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4242 - accuracy: 0.7957 - val_loss: 0.4259 - val_accuracy: 0.7924\n",
      "Epoch 163/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4237 - accuracy: 0.7963 - val_loss: 0.4260 - val_accuracy: 0.7928\n",
      "Epoch 164/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4238 - accuracy: 0.7965 - val_loss: 0.4261 - val_accuracy: 0.7939\n",
      "Epoch 165/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.7967 - val_loss: 0.4257 - val_accuracy: 0.7923\n",
      "Epoch 166/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.7974 - val_loss: 0.4244 - val_accuracy: 0.7930\n",
      "Epoch 167/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.7971 - val_loss: 0.4247 - val_accuracy: 0.7929\n",
      "Epoch 168/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4231 - accuracy: 0.7975 - val_loss: 0.4246 - val_accuracy: 0.7931\n",
      "Epoch 169/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.7967 - val_loss: 0.4235 - val_accuracy: 0.7945\n",
      "Epoch 170/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.7977 - val_loss: 0.4237 - val_accuracy: 0.7942\n",
      "Epoch 171/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.7971 - val_loss: 0.4237 - val_accuracy: 0.7939\n",
      "Epoch 172/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4225 - accuracy: 0.7973 - val_loss: 0.4248 - val_accuracy: 0.7950\n",
      "Epoch 173/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.7973 - val_loss: 0.4234 - val_accuracy: 0.7951\n",
      "Epoch 174/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.7984 - val_loss: 0.4244 - val_accuracy: 0.7954\n",
      "Epoch 175/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.7987 - val_loss: 0.4233 - val_accuracy: 0.7948\n",
      "Epoch 176/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.7993 - val_loss: 0.4232 - val_accuracy: 0.7950\n",
      "Epoch 177/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.7990 - val_loss: 0.4232 - val_accuracy: 0.7948\n",
      "Epoch 178/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.7987 - val_loss: 0.4239 - val_accuracy: 0.7950\n",
      "Epoch 179/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.7996 - val_loss: 0.4239 - val_accuracy: 0.7938\n",
      "Epoch 180/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.7996 - val_loss: 0.4233 - val_accuracy: 0.7945\n",
      "Epoch 181/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.7991 - val_loss: 0.4231 - val_accuracy: 0.7959\n",
      "Epoch 182/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.8002 - val_loss: 0.4220 - val_accuracy: 0.7967\n",
      "Epoch 183/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.7995 - val_loss: 0.4238 - val_accuracy: 0.7944\n",
      "Epoch 184/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.8005 - val_loss: 0.4218 - val_accuracy: 0.7970\n",
      "Epoch 185/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.7996 - val_loss: 0.4222 - val_accuracy: 0.7954\n",
      "Epoch 186/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8013 - val_loss: 0.4220 - val_accuracy: 0.7968\n",
      "Epoch 187/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8016 - val_loss: 0.4220 - val_accuracy: 0.7959\n",
      "Epoch 188/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8011 - val_loss: 0.4215 - val_accuracy: 0.7984\n",
      "Epoch 189/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8011 - val_loss: 0.4235 - val_accuracy: 0.7974\n",
      "Epoch 190/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8007 - val_loss: 0.4210 - val_accuracy: 0.7984\n",
      "Epoch 191/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8014 - val_loss: 0.4212 - val_accuracy: 0.7984\n",
      "Epoch 192/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8024 - val_loss: 0.4203 - val_accuracy: 0.7992\n",
      "Epoch 193/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8015 - val_loss: 0.4209 - val_accuracy: 0.7958\n",
      "Epoch 194/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8015 - val_loss: 0.4207 - val_accuracy: 0.7995\n",
      "Epoch 195/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4193 - accuracy: 0.8017 - val_loss: 0.4201 - val_accuracy: 0.7997\n",
      "Epoch 196/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8025 - val_loss: 0.4207 - val_accuracy: 0.7989\n",
      "Epoch 197/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8018 - val_loss: 0.4194 - val_accuracy: 0.8001\n",
      "Epoch 198/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8022 - val_loss: 0.4196 - val_accuracy: 0.8004\n",
      "Epoch 199/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8026 - val_loss: 0.4196 - val_accuracy: 0.7996\n",
      "Epoch 200/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8027 - val_loss: 0.4195 - val_accuracy: 0.7992\n",
      "Epoch 201/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8031 - val_loss: 0.4206 - val_accuracy: 0.8017\n",
      "Epoch 202/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8034 - val_loss: 0.4194 - val_accuracy: 0.8016\n",
      "Epoch 203/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8044 - val_loss: 0.4198 - val_accuracy: 0.7983\n",
      "Epoch 204/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8032 - val_loss: 0.4188 - val_accuracy: 0.8023\n",
      "Epoch 205/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8045 - val_loss: 0.4200 - val_accuracy: 0.8020\n",
      "Epoch 206/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8039 - val_loss: 0.4187 - val_accuracy: 0.7998\n",
      "Epoch 207/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8047 - val_loss: 0.4189 - val_accuracy: 0.8023\n",
      "Epoch 208/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4170 - accuracy: 0.8041 - val_loss: 0.4195 - val_accuracy: 0.7992\n",
      "Epoch 209/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8047 - val_loss: 0.4180 - val_accuracy: 0.8014\n",
      "Epoch 210/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8046 - val_loss: 0.4200 - val_accuracy: 0.7994\n",
      "Epoch 211/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8052 - val_loss: 0.4185 - val_accuracy: 0.8015\n",
      "Epoch 212/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8057 - val_loss: 0.4185 - val_accuracy: 0.8013\n",
      "Epoch 213/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8059 - val_loss: 0.4174 - val_accuracy: 0.8015\n",
      "Epoch 214/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8049 - val_loss: 0.4170 - val_accuracy: 0.8025\n",
      "Epoch 215/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8061 - val_loss: 0.4180 - val_accuracy: 0.8022\n",
      "Epoch 216/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8053 - val_loss: 0.4185 - val_accuracy: 0.8006\n",
      "Epoch 217/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8055 - val_loss: 0.4177 - val_accuracy: 0.8013\n",
      "Epoch 218/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8064 - val_loss: 0.4167 - val_accuracy: 0.8019\n",
      "Epoch 219/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8059 - val_loss: 0.4173 - val_accuracy: 0.8018\n",
      "Epoch 220/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8058 - val_loss: 0.4180 - val_accuracy: 0.8030\n",
      "Epoch 221/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.4166 - val_accuracy: 0.8030\n",
      "Epoch 222/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8068 - val_loss: 0.4162 - val_accuracy: 0.8040\n",
      "Epoch 223/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8065 - val_loss: 0.4158 - val_accuracy: 0.8035\n",
      "Epoch 224/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8061 - val_loss: 0.4166 - val_accuracy: 0.8030\n",
      "Epoch 225/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8072 - val_loss: 0.4160 - val_accuracy: 0.8043\n",
      "Epoch 226/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8071 - val_loss: 0.4169 - val_accuracy: 0.8035\n",
      "Epoch 227/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8076 - val_loss: 0.4160 - val_accuracy: 0.8048\n",
      "Epoch 228/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8071 - val_loss: 0.4159 - val_accuracy: 0.8056\n",
      "Epoch 229/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8075 - val_loss: 0.4166 - val_accuracy: 0.8038\n",
      "Epoch 230/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8073 - val_loss: 0.4158 - val_accuracy: 0.8035\n",
      "Epoch 231/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8089 - val_loss: 0.4151 - val_accuracy: 0.8058\n",
      "Epoch 232/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8091 - val_loss: 0.4151 - val_accuracy: 0.8057\n",
      "Epoch 233/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8083 - val_loss: 0.4147 - val_accuracy: 0.8061\n",
      "Epoch 234/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8085 - val_loss: 0.4146 - val_accuracy: 0.8057\n",
      "Epoch 235/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8084 - val_loss: 0.4149 - val_accuracy: 0.8058\n",
      "Epoch 236/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4129 - accuracy: 0.8087 - val_loss: 0.4163 - val_accuracy: 0.8055\n",
      "Epoch 237/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8085 - val_loss: 0.4166 - val_accuracy: 0.8043\n",
      "Epoch 238/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8094 - val_loss: 0.4154 - val_accuracy: 0.8058\n",
      "Epoch 239/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8091 - val_loss: 0.4137 - val_accuracy: 0.8059\n",
      "Epoch 240/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8092 - val_loss: 0.4137 - val_accuracy: 0.8065\n",
      "Epoch 241/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8101 - val_loss: 0.4139 - val_accuracy: 0.8073\n",
      "Epoch 242/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8082 - val_loss: 0.4140 - val_accuracy: 0.8065\n",
      "Epoch 243/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8098 - val_loss: 0.4143 - val_accuracy: 0.8078\n",
      "Epoch 244/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8096 - val_loss: 0.4136 - val_accuracy: 0.8074\n",
      "Epoch 245/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8105 - val_loss: 0.4132 - val_accuracy: 0.8072\n",
      "Epoch 246/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8099 - val_loss: 0.4133 - val_accuracy: 0.8075\n",
      "Epoch 247/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8110 - val_loss: 0.4136 - val_accuracy: 0.8075\n",
      "Epoch 248/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8102 - val_loss: 0.4160 - val_accuracy: 0.8040\n",
      "Epoch 249/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8104 - val_loss: 0.4129 - val_accuracy: 0.8081\n",
      "Epoch 250/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8112 - val_loss: 0.4128 - val_accuracy: 0.8082\n",
      "Epoch 251/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4110 - accuracy: 0.8105 - val_loss: 0.4136 - val_accuracy: 0.8079\n",
      "Epoch 252/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8107 - val_loss: 0.4130 - val_accuracy: 0.8072\n",
      "Epoch 253/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8110 - val_loss: 0.4118 - val_accuracy: 0.8093\n",
      "Epoch 254/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8113 - val_loss: 0.4133 - val_accuracy: 0.8087\n",
      "Epoch 255/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8110 - val_loss: 0.4148 - val_accuracy: 0.8059\n",
      "Epoch 256/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8112 - val_loss: 0.4123 - val_accuracy: 0.8081\n",
      "Epoch 257/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8109 - val_loss: 0.4115 - val_accuracy: 0.8097\n",
      "Epoch 258/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8123 - val_loss: 0.4120 - val_accuracy: 0.8097\n",
      "Epoch 259/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8113 - val_loss: 0.4122 - val_accuracy: 0.8094\n",
      "Epoch 260/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8114 - val_loss: 0.4119 - val_accuracy: 0.8090\n",
      "Epoch 261/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8119 - val_loss: 0.4115 - val_accuracy: 0.8080\n",
      "Epoch 262/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8124 - val_loss: 0.4120 - val_accuracy: 0.8095\n",
      "Epoch 263/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.4132 - val_accuracy: 0.8065\n",
      "Epoch 264/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.4107 - val_accuracy: 0.8101\n",
      "Epoch 265/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8128 - val_loss: 0.4111 - val_accuracy: 0.8097\n",
      "Epoch 266/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4091 - accuracy: 0.8129 - val_loss: 0.4118 - val_accuracy: 0.8096\n",
      "Epoch 267/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8123 - val_loss: 0.4121 - val_accuracy: 0.8082\n",
      "Epoch 268/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8126 - val_loss: 0.4119 - val_accuracy: 0.8089\n",
      "Epoch 269/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8122 - val_loss: 0.4101 - val_accuracy: 0.8112\n",
      "Epoch 270/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8129 - val_loss: 0.4106 - val_accuracy: 0.8101\n",
      "Epoch 271/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8126 - val_loss: 0.4109 - val_accuracy: 0.8105\n",
      "Epoch 272/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8137 - val_loss: 0.4099 - val_accuracy: 0.8112\n",
      "Epoch 273/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8129 - val_loss: 0.4100 - val_accuracy: 0.8109\n",
      "Epoch 274/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8132 - val_loss: 0.4130 - val_accuracy: 0.8057\n",
      "Epoch 275/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8132 - val_loss: 0.4100 - val_accuracy: 0.8111\n",
      "Epoch 276/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8136 - val_loss: 0.4090 - val_accuracy: 0.8127\n",
      "Epoch 277/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8133 - val_loss: 0.4103 - val_accuracy: 0.8102\n",
      "Epoch 278/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8144 - val_loss: 0.4085 - val_accuracy: 0.8137\n",
      "Epoch 279/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8137 - val_loss: 0.4092 - val_accuracy: 0.8116\n",
      "Epoch 280/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8134 - val_loss: 0.4115 - val_accuracy: 0.8088\n",
      "Epoch 281/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8135 - val_loss: 0.4100 - val_accuracy: 0.8094\n",
      "Epoch 282/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4077 - accuracy: 0.8143 - val_loss: 0.4088 - val_accuracy: 0.8122\n",
      "Epoch 283/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8142 - val_loss: 0.4083 - val_accuracy: 0.8139\n",
      "Epoch 284/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8136 - val_loss: 0.4112 - val_accuracy: 0.8078\n",
      "Epoch 285/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8142 - val_loss: 0.4091 - val_accuracy: 0.8124\n",
      "Epoch 286/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8143 - val_loss: 0.4097 - val_accuracy: 0.8102\n",
      "Epoch 287/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8144 - val_loss: 0.4084 - val_accuracy: 0.8143\n",
      "Epoch 288/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8147 - val_loss: 0.4083 - val_accuracy: 0.8142\n",
      "Epoch 289/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8153 - val_loss: 0.4080 - val_accuracy: 0.8138\n",
      "Epoch 290/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8155 - val_loss: 0.4079 - val_accuracy: 0.8129\n",
      "Epoch 291/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8153 - val_loss: 0.4075 - val_accuracy: 0.8127\n",
      "Epoch 292/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8146 - val_loss: 0.4080 - val_accuracy: 0.8131\n",
      "Epoch 293/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8145 - val_loss: 0.4091 - val_accuracy: 0.8119\n",
      "Epoch 294/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8154 - val_loss: 0.4084 - val_accuracy: 0.8116\n",
      "Epoch 295/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8158 - val_loss: 0.4079 - val_accuracy: 0.8145\n",
      "Epoch 296/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8155 - val_loss: 0.4082 - val_accuracy: 0.8133\n",
      "Epoch 297/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8162 - val_loss: 0.4072 - val_accuracy: 0.8146\n",
      "Epoch 298/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4059 - accuracy: 0.8156 - val_loss: 0.4069 - val_accuracy: 0.8148\n",
      "Epoch 299/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8164 - val_loss: 0.4070 - val_accuracy: 0.8134\n",
      "Epoch 300/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8157 - val_loss: 0.4081 - val_accuracy: 0.8136\n",
      "Epoch 301/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8159 - val_loss: 0.4076 - val_accuracy: 0.8134\n",
      "Epoch 302/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8167 - val_loss: 0.4079 - val_accuracy: 0.8122\n",
      "Epoch 303/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8163 - val_loss: 0.4091 - val_accuracy: 0.8120\n",
      "Epoch 304/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8172 - val_loss: 0.4088 - val_accuracy: 0.8107\n",
      "Epoch 305/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8167 - val_loss: 0.4071 - val_accuracy: 0.8145\n",
      "Epoch 306/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8174 - val_loss: 0.4082 - val_accuracy: 0.8132\n",
      "Epoch 307/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8171 - val_loss: 0.4068 - val_accuracy: 0.8157\n",
      "Epoch 308/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8171 - val_loss: 0.4062 - val_accuracy: 0.8151\n",
      "Epoch 309/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8170 - val_loss: 0.4073 - val_accuracy: 0.8144\n",
      "Epoch 310/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8171 - val_loss: 0.4081 - val_accuracy: 0.8121\n",
      "Epoch 311/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8169 - val_loss: 0.4068 - val_accuracy: 0.8145\n",
      "Epoch 312/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8180 - val_loss: 0.4068 - val_accuracy: 0.8146\n",
      "Epoch 313/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8170 - val_loss: 0.4061 - val_accuracy: 0.8154\n",
      "Epoch 314/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8173 - val_loss: 0.4060 - val_accuracy: 0.8154\n",
      "Epoch 315/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4040 - accuracy: 0.8169 - val_loss: 0.4082 - val_accuracy: 0.8123\n",
      "Epoch 316/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8171 - val_loss: 0.4078 - val_accuracy: 0.8126\n",
      "Epoch 317/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8176 - val_loss: 0.4053 - val_accuracy: 0.8155\n",
      "Epoch 318/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8176 - val_loss: 0.4052 - val_accuracy: 0.8161\n",
      "Epoch 319/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8176 - val_loss: 0.4056 - val_accuracy: 0.8158\n",
      "Epoch 320/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8180 - val_loss: 0.4076 - val_accuracy: 0.8133\n",
      "Epoch 321/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8184 - val_loss: 0.4063 - val_accuracy: 0.8146\n",
      "Epoch 322/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8178 - val_loss: 0.4061 - val_accuracy: 0.8164\n",
      "Epoch 323/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8179 - val_loss: 0.4056 - val_accuracy: 0.8163\n",
      "Epoch 324/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8181 - val_loss: 0.4060 - val_accuracy: 0.8164\n",
      "Epoch 325/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4036 - accuracy: 0.8185 - val_loss: 0.4051 - val_accuracy: 0.8166\n",
      "Epoch 326/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8186 - val_loss: 0.4069 - val_accuracy: 0.8131\n",
      "Epoch 327/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8183 - val_loss: 0.4054 - val_accuracy: 0.8168\n",
      "Epoch 328/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8178 - val_loss: 0.4072 - val_accuracy: 0.8134\n",
      "Epoch 329/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8191 - val_loss: 0.4054 - val_accuracy: 0.8150\n",
      "Epoch 330/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4034 - accuracy: 0.8193 - val_loss: 0.4062 - val_accuracy: 0.8138\n",
      "Epoch 331/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4035 - accuracy: 0.8195 - val_loss: 0.4061 - val_accuracy: 0.8169\n",
      "Epoch 332/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8184 - val_loss: 0.4048 - val_accuracy: 0.8174\n",
      "Epoch 333/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8199 - val_loss: 0.4048 - val_accuracy: 0.8178\n",
      "Epoch 334/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8190 - val_loss: 0.4045 - val_accuracy: 0.8177\n",
      "Epoch 335/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8196 - val_loss: 0.4067 - val_accuracy: 0.8158\n",
      "Epoch 336/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8191 - val_loss: 0.4041 - val_accuracy: 0.8172\n",
      "Epoch 337/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8190 - val_loss: 0.4053 - val_accuracy: 0.8174\n",
      "Epoch 338/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8195 - val_loss: 0.4046 - val_accuracy: 0.8181\n",
      "Epoch 339/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8196 - val_loss: 0.4054 - val_accuracy: 0.8144\n",
      "Epoch 340/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4028 - accuracy: 0.8195 - val_loss: 0.4050 - val_accuracy: 0.8178\n",
      "Epoch 341/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4025 - accuracy: 0.8201 - val_loss: 0.4045 - val_accuracy: 0.8187\n",
      "Epoch 342/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4029 - accuracy: 0.8196 - val_loss: 0.4042 - val_accuracy: 0.8169\n",
      "Epoch 343/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8192 - val_loss: 0.4056 - val_accuracy: 0.8178\n",
      "Epoch 344/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8198 - val_loss: 0.4043 - val_accuracy: 0.8181\n",
      "Epoch 345/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4025 - accuracy: 0.8201 - val_loss: 0.4048 - val_accuracy: 0.8164\n",
      "Epoch 346/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4023 - accuracy: 0.8197 - val_loss: 0.4051 - val_accuracy: 0.8161\n",
      "Epoch 347/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8196 - val_loss: 0.4087 - val_accuracy: 0.8117\n",
      "Epoch 348/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8197 - val_loss: 0.4049 - val_accuracy: 0.8160\n",
      "Epoch 349/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8205 - val_loss: 0.4043 - val_accuracy: 0.8160\n",
      "Epoch 350/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4024 - accuracy: 0.8201 - val_loss: 0.4052 - val_accuracy: 0.8160\n",
      "Epoch 351/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8200 - val_loss: 0.4039 - val_accuracy: 0.8186\n",
      "Epoch 352/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8189 - val_loss: 0.4059 - val_accuracy: 0.8168\n",
      "Epoch 353/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4025 - accuracy: 0.8197 - val_loss: 0.4048 - val_accuracy: 0.8187\n",
      "Epoch 354/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8200 - val_loss: 0.4062 - val_accuracy: 0.8163\n",
      "Epoch 355/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4019 - accuracy: 0.8202 - val_loss: 0.4040 - val_accuracy: 0.8171\n",
      "Epoch 356/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8206 - val_loss: 0.4039 - val_accuracy: 0.8167\n",
      "Epoch 357/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8196 - val_loss: 0.4041 - val_accuracy: 0.8177\n",
      "Epoch 358/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.8200 - val_loss: 0.4046 - val_accuracy: 0.8183\n",
      "Epoch 359/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4017 - accuracy: 0.8215 - val_loss: 0.4041 - val_accuracy: 0.8173\n",
      "Epoch 360/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4024 - accuracy: 0.8193 - val_loss: 0.4053 - val_accuracy: 0.8165\n",
      "Epoch 361/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8201 - val_loss: 0.4035 - val_accuracy: 0.8184\n",
      "Epoch 362/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8203 - val_loss: 0.4048 - val_accuracy: 0.8177\n",
      "Epoch 363/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8206 - val_loss: 0.4053 - val_accuracy: 0.8157\n",
      "Epoch 364/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8217 - val_loss: 0.4041 - val_accuracy: 0.8168\n",
      "Epoch 365/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4014 - accuracy: 0.8208 - val_loss: 0.4069 - val_accuracy: 0.8142\n",
      "Epoch 366/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4028 - accuracy: 0.8197 - val_loss: 0.4041 - val_accuracy: 0.8186\n",
      "Epoch 367/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8207 - val_loss: 0.4042 - val_accuracy: 0.8199\n",
      "Epoch 368/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8210 - val_loss: 0.4031 - val_accuracy: 0.8177\n",
      "Epoch 369/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8208 - val_loss: 0.4054 - val_accuracy: 0.8159\n",
      "Epoch 370/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8214 - val_loss: 0.4039 - val_accuracy: 0.8194\n",
      "Epoch 371/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4023 - accuracy: 0.8199 - val_loss: 0.4032 - val_accuracy: 0.8199\n",
      "Epoch 372/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8212 - val_loss: 0.4035 - val_accuracy: 0.8185\n",
      "Epoch 373/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8217 - val_loss: 0.4043 - val_accuracy: 0.8170\n",
      "Epoch 374/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4016 - accuracy: 0.8212 - val_loss: 0.4030 - val_accuracy: 0.8195\n",
      "Epoch 375/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8209 - val_loss: 0.4044 - val_accuracy: 0.8167\n",
      "Epoch 376/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4015 - accuracy: 0.8214 - val_loss: 0.4041 - val_accuracy: 0.8172\n",
      "Epoch 377/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8212 - val_loss: 0.4029 - val_accuracy: 0.8195\n",
      "Epoch 378/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4016 - accuracy: 0.8210 - val_loss: 0.4029 - val_accuracy: 0.8201\n",
      "Epoch 379/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4014 - accuracy: 0.8216 - val_loss: 0.4029 - val_accuracy: 0.8179\n",
      "Epoch 380/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8210 - val_loss: 0.4037 - val_accuracy: 0.8189\n",
      "Epoch 381/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4011 - accuracy: 0.8208 - val_loss: 0.4046 - val_accuracy: 0.8173\n",
      "Epoch 382/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4014 - accuracy: 0.8209 - val_loss: 0.4037 - val_accuracy: 0.8163\n",
      "Epoch 383/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4009 - accuracy: 0.8207 - val_loss: 0.4032 - val_accuracy: 0.8177\n",
      "Epoch 384/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4009 - accuracy: 0.8205 - val_loss: 0.4040 - val_accuracy: 0.8169\n",
      "Epoch 385/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4007 - accuracy: 0.8216 - val_loss: 0.4027 - val_accuracy: 0.8177\n",
      "Epoch 386/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4012 - accuracy: 0.8212 - val_loss: 0.4031 - val_accuracy: 0.8173\n",
      "Epoch 387/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4007 - accuracy: 0.8215 - val_loss: 0.4027 - val_accuracy: 0.8195\n",
      "Epoch 388/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4009 - accuracy: 0.8216 - val_loss: 0.4036 - val_accuracy: 0.8179\n",
      "Epoch 389/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8217 - val_loss: 0.4029 - val_accuracy: 0.8187\n",
      "Epoch 390/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8207 - val_loss: 0.4042 - val_accuracy: 0.8158\n",
      "Epoch 391/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8211 - val_loss: 0.4026 - val_accuracy: 0.8195\n",
      "Epoch 392/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8216 - val_loss: 0.4031 - val_accuracy: 0.8185\n",
      "Epoch 393/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8224 - val_loss: 0.4034 - val_accuracy: 0.8197\n",
      "Epoch 394/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8201 - val_loss: 0.4046 - val_accuracy: 0.8154\n",
      "Epoch 395/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4009 - accuracy: 0.8216 - val_loss: 0.4027 - val_accuracy: 0.8188\n",
      "Epoch 396/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8211 - val_loss: 0.4029 - val_accuracy: 0.8171\n",
      "Epoch 397/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8216 - val_loss: 0.4041 - val_accuracy: 0.8173\n",
      "Epoch 398/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8220 - val_loss: 0.4023 - val_accuracy: 0.8190\n",
      "Epoch 399/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8216 - val_loss: 0.4046 - val_accuracy: 0.8192\n",
      "Epoch 400/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8214 - val_loss: 0.4037 - val_accuracy: 0.8174\n",
      "Epoch 401/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4009 - accuracy: 0.8214 - val_loss: 0.4024 - val_accuracy: 0.8173\n",
      "Epoch 402/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.8213 - val_loss: 0.4042 - val_accuracy: 0.8174\n",
      "Epoch 403/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8215 - val_loss: 0.4039 - val_accuracy: 0.8163\n",
      "Epoch 404/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8220 - val_loss: 0.4033 - val_accuracy: 0.8167\n",
      "Epoch 405/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.8220 - val_loss: 0.4028 - val_accuracy: 0.8198\n",
      "Epoch 406/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4004 - accuracy: 0.8217 - val_loss: 0.4058 - val_accuracy: 0.8174\n",
      "Epoch 407/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8215 - val_loss: 0.4025 - val_accuracy: 0.8199\n",
      "Epoch 408/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8218 - val_loss: 0.4048 - val_accuracy: 0.8167\n",
      "Epoch 409/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4002 - accuracy: 0.8223 - val_loss: 0.4033 - val_accuracy: 0.8192\n",
      "Epoch 410/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4002 - accuracy: 0.8216 - val_loss: 0.4021 - val_accuracy: 0.8187\n",
      "Epoch 411/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8218 - val_loss: 0.4031 - val_accuracy: 0.8179\n",
      "Epoch 412/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8222 - val_loss: 0.4030 - val_accuracy: 0.8174\n",
      "Epoch 413/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4001 - accuracy: 0.8213 - val_loss: 0.4024 - val_accuracy: 0.8172\n",
      "Epoch 414/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4002 - accuracy: 0.8223 - val_loss: 0.4025 - val_accuracy: 0.8208\n",
      "Epoch 415/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8224 - val_loss: 0.4025 - val_accuracy: 0.8194\n",
      "Epoch 416/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8229 - val_loss: 0.4030 - val_accuracy: 0.8194\n",
      "Epoch 417/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4001 - accuracy: 0.8223 - val_loss: 0.4024 - val_accuracy: 0.8186\n",
      "Epoch 418/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8218 - val_loss: 0.4030 - val_accuracy: 0.8192\n",
      "Epoch 419/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8226 - val_loss: 0.4020 - val_accuracy: 0.8180\n",
      "Epoch 420/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4004 - accuracy: 0.8220 - val_loss: 0.4029 - val_accuracy: 0.8190\n",
      "Epoch 421/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8217 - val_loss: 0.4021 - val_accuracy: 0.8201\n",
      "Epoch 422/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.8225 - val_loss: 0.4023 - val_accuracy: 0.8183\n",
      "Epoch 423/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8217 - val_loss: 0.4030 - val_accuracy: 0.8190\n",
      "Epoch 424/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8223 - val_loss: 0.4029 - val_accuracy: 0.8172\n",
      "Epoch 425/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8219 - val_loss: 0.4026 - val_accuracy: 0.8184\n",
      "Epoch 426/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8217 - val_loss: 0.4049 - val_accuracy: 0.8143\n",
      "Epoch 427/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.8209 - val_loss: 0.4023 - val_accuracy: 0.8187\n",
      "Epoch 428/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3997 - accuracy: 0.8223 - val_loss: 0.4025 - val_accuracy: 0.8192\n",
      "Epoch 429/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8220 - val_loss: 0.4020 - val_accuracy: 0.8165\n",
      "Epoch 430/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8224 - val_loss: 0.4028 - val_accuracy: 0.8180\n",
      "Epoch 431/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3994 - accuracy: 0.8224 - val_loss: 0.4015 - val_accuracy: 0.8190\n",
      "Epoch 432/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8220 - val_loss: 0.4015 - val_accuracy: 0.8197\n",
      "Epoch 433/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8231 - val_loss: 0.4017 - val_accuracy: 0.8206\n",
      "Epoch 434/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8227 - val_loss: 0.4026 - val_accuracy: 0.8169\n",
      "Epoch 435/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3996 - accuracy: 0.8218 - val_loss: 0.4022 - val_accuracy: 0.8202\n",
      "Epoch 436/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3995 - accuracy: 0.8223 - val_loss: 0.4017 - val_accuracy: 0.8199\n",
      "Epoch 437/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3995 - accuracy: 0.8222 - val_loss: 0.4026 - val_accuracy: 0.8162\n",
      "Epoch 438/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3998 - accuracy: 0.8221 - val_loss: 0.4019 - val_accuracy: 0.8218\n",
      "Epoch 439/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8217 - val_loss: 0.4016 - val_accuracy: 0.8189\n",
      "Epoch 440/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8226 - val_loss: 0.4016 - val_accuracy: 0.8206\n",
      "Epoch 441/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.4000 - accuracy: 0.8218 - val_loss: 0.4020 - val_accuracy: 0.8170\n",
      "Epoch 442/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3993 - accuracy: 0.8228 - val_loss: 0.4028 - val_accuracy: 0.8174\n",
      "Epoch 443/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.8237 - val_loss: 0.4018 - val_accuracy: 0.8200\n",
      "Epoch 444/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3996 - accuracy: 0.8222 - val_loss: 0.4030 - val_accuracy: 0.8172\n",
      "Epoch 445/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3994 - accuracy: 0.8222 - val_loss: 0.4028 - val_accuracy: 0.8161\n",
      "Epoch 446/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8226 - val_loss: 0.4020 - val_accuracy: 0.8211\n",
      "Epoch 447/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3997 - accuracy: 0.8237 - val_loss: 0.4029 - val_accuracy: 0.8173\n",
      "Epoch 448/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3997 - accuracy: 0.8221 - val_loss: 0.4033 - val_accuracy: 0.8203\n",
      "Epoch 449/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8226 - val_loss: 0.4031 - val_accuracy: 0.8171\n",
      "Epoch 450/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8228 - val_loss: 0.4042 - val_accuracy: 0.8163\n",
      "Epoch 451/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3995 - accuracy: 0.8233 - val_loss: 0.4018 - val_accuracy: 0.8190\n",
      "Epoch 452/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8231 - val_loss: 0.4023 - val_accuracy: 0.8187\n",
      "Epoch 453/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8234 - val_loss: 0.4015 - val_accuracy: 0.8209\n",
      "Epoch 454/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8230 - val_loss: 0.4015 - val_accuracy: 0.8197\n",
      "Epoch 455/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.4021 - val_accuracy: 0.8176\n",
      "Epoch 456/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8235 - val_loss: 0.4018 - val_accuracy: 0.8208\n",
      "Epoch 457/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8226 - val_loss: 0.4015 - val_accuracy: 0.8181\n",
      "Epoch 458/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8225 - val_loss: 0.4010 - val_accuracy: 0.8197\n",
      "Epoch 459/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8220 - val_loss: 0.4016 - val_accuracy: 0.8185\n",
      "Epoch 460/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3990 - accuracy: 0.8220 - val_loss: 0.4017 - val_accuracy: 0.8214\n",
      "Epoch 461/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8234 - val_loss: 0.4031 - val_accuracy: 0.8189\n",
      "Epoch 462/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8216 - val_loss: 0.4005 - val_accuracy: 0.8194\n",
      "Epoch 463/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8221 - val_loss: 0.4022 - val_accuracy: 0.8197\n",
      "Epoch 464/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.8230 - val_loss: 0.4013 - val_accuracy: 0.8195\n",
      "Epoch 465/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8225 - val_loss: 0.4003 - val_accuracy: 0.8202\n",
      "Epoch 466/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3993 - accuracy: 0.8221 - val_loss: 0.4038 - val_accuracy: 0.8145\n",
      "Epoch 467/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.8231 - val_loss: 0.4017 - val_accuracy: 0.8209\n",
      "Epoch 468/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.4007 - val_accuracy: 0.8194\n",
      "Epoch 469/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8232 - val_loss: 0.4017 - val_accuracy: 0.8207\n",
      "Epoch 470/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8219 - val_loss: 0.4021 - val_accuracy: 0.8200\n",
      "Epoch 471/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8226 - val_loss: 0.4019 - val_accuracy: 0.8194\n",
      "Epoch 472/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8233 - val_loss: 0.4015 - val_accuracy: 0.8178\n",
      "Epoch 473/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8242 - val_loss: 0.4011 - val_accuracy: 0.8192\n",
      "Epoch 474/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3985 - accuracy: 0.8226 - val_loss: 0.4018 - val_accuracy: 0.8187\n",
      "Epoch 475/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.8227 - val_loss: 0.4022 - val_accuracy: 0.8204\n",
      "Epoch 476/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.4047 - val_accuracy: 0.8135\n",
      "Epoch 477/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3985 - accuracy: 0.8230 - val_loss: 0.4013 - val_accuracy: 0.8210\n",
      "Epoch 478/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8200\n",
      "Epoch 479/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3983 - accuracy: 0.8231 - val_loss: 0.4011 - val_accuracy: 0.8211\n",
      "Epoch 480/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8233 - val_loss: 0.4006 - val_accuracy: 0.8205\n",
      "Epoch 481/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.4004 - val_accuracy: 0.8210\n",
      "Epoch 482/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3985 - accuracy: 0.8230 - val_loss: 0.4034 - val_accuracy: 0.8185\n",
      "Epoch 483/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3986 - accuracy: 0.8235 - val_loss: 0.4022 - val_accuracy: 0.8162\n",
      "Epoch 484/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3985 - accuracy: 0.8230 - val_loss: 0.4005 - val_accuracy: 0.8216\n",
      "Epoch 485/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8206\n",
      "Epoch 486/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3992 - accuracy: 0.8225 - val_loss: 0.4012 - val_accuracy: 0.8187\n",
      "Epoch 487/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8230 - val_loss: 0.4008 - val_accuracy: 0.8202\n",
      "Epoch 488/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.8231 - val_loss: 0.4030 - val_accuracy: 0.8167\n",
      "Epoch 489/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3989 - accuracy: 0.8215 - val_loss: 0.4021 - val_accuracy: 0.8173\n",
      "Epoch 490/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3978 - accuracy: 0.8237 - val_loss: 0.4017 - val_accuracy: 0.8173\n",
      "Epoch 491/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3987 - accuracy: 0.8228 - val_loss: 0.4013 - val_accuracy: 0.8186\n",
      "Epoch 492/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3985 - accuracy: 0.8232 - val_loss: 0.4010 - val_accuracy: 0.8197\n",
      "Epoch 493/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3981 - accuracy: 0.8238 - val_loss: 0.4009 - val_accuracy: 0.8205\n",
      "Epoch 494/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3983 - accuracy: 0.8223 - val_loss: 0.4015 - val_accuracy: 0.8188\n",
      "Epoch 495/500\n",
      "125/125 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8231 - val_loss: 0.4046 - val_accuracy: 0.8153\n",
      "Epoch 496/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3990 - accuracy: 0.8219 - val_loss: 0.4006 - val_accuracy: 0.8217\n",
      "Epoch 497/500\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.3979 - accuracy: 0.8237 - val_loss: 0.4001 - val_accuracy: 0.8206\n",
      "Epoch 498/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3976 - accuracy: 0.8238 - val_loss: 0.4018 - val_accuracy: 0.8207\n",
      "Epoch 499/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3978 - accuracy: 0.8232 - val_loss: 0.4041 - val_accuracy: 0.8152\n",
      "Epoch 500/500\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3982 - accuracy: 0.8230 - val_loss: 0.4017 - val_accuracy: 0.8173\n"
     ]
    }
   ],
   "source": [
    "# We will now begin training the FCNN with the training data we encoded earlier, using the hyperparameters we defined.\n",
    "# To prevent overcorrection or memorization of the data, we will dedicate 20% of the data to validation. We will store\n",
    "# the results of the training session for later analysis.\n",
    "FCNN_results = FCNN.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=KERAS_EPOCHS,\n",
    "                        batch_size=KERAS_BATCHES,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 64)             6365888   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 4)                 1104      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 6,366,997\n",
      "Trainable params: 6,366,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now, we will create the recurrent neural network in a similar fashion.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "# Create the FCNN. This will have a first layer that maps to the number of characters in our set: in this case, 8. We\n",
    "# also include some hidden layers of various lengths before including a final layer that will filter down to a single\n",
    "# input.\n",
    "RNN = keras.Sequential()\n",
    "RNN.add(Embedding(DATASET_COUNT + 1, 64, input_length=8))\n",
    "RNN.add(LSTM(4, activation='tanh'))\n",
    "RNN.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model and use 'binary cross-entropy' to foce the network to either say \"yes\" or \"no\". We will also use the\n",
    "# adam optimizer and list accuracy in our metrics for further analysis.\n",
    "RNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print out a summary of the FCNN.\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "125/125 [==============================] - 6s 39ms/step - loss: 0.6622 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 2/500\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6548 - val_accuracy: 0.6382\n",
      "Epoch 3/500\n",
      "125/125 [==============================] - 5s 38ms/step - loss: 0.6527 - accuracy: 0.6414 - val_loss: 0.6547 - val_accuracy: 0.6382\n",
      "Epoch 4/500\n",
      "125/125 [==============================] - 5s 38ms/step - loss: 0.6527 - accuracy: 0.6414 - val_loss: 0.6545 - val_accuracy: 0.6382\n",
      "Epoch 5/500\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6547 - val_accuracy: 0.6382\n",
      "Epoch 6/500\n",
      "125/125 [==============================] - 4s 36ms/step - loss: 0.6527 - accuracy: 0.6414 - val_loss: 0.6548 - val_accuracy: 0.6382\n",
      "Epoch 7/500\n",
      "125/125 [==============================] - 5s 37ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 8/500\n",
      "125/125 [==============================] - 5s 36ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 9/500\n",
      "125/125 [==============================] - 4s 36ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 10/500\n",
      "125/125 [==============================] - 4s 36ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 11/500\n",
      "125/125 [==============================] - 4s 35ms/step - loss: 0.6526 - accuracy: 0.6414 - val_loss: 0.6544 - val_accuracy: 0.6382\n",
      "Epoch 12/500\n",
      "125/125 [==============================] - 4s 35ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 13/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 14/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 15/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 16/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 17/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 18/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 19/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 20/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 21/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 22/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 23/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 24/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 25/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 26/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 27/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 28/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 29/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 30/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 31/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 32/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 33/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 34/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 35/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 36/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 37/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 38/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 39/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 40/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 41/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 42/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 43/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 44/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 45/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 46/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 47/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 48/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 49/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 50/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 51/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 52/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 53/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 54/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 55/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 56/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 57/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 58/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 59/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 60/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 61/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 62/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 63/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 64/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 65/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 66/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 67/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 68/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 69/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 70/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 71/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 72/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 73/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 74/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 75/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 76/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 77/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 78/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 79/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 80/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 81/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 82/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 83/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 84/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 85/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 86/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 87/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 88/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 89/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 90/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 91/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 92/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 93/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 94/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 95/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 96/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 97/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 98/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 99/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 100/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 101/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 102/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 103/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 104/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 105/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 106/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 107/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 108/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 109/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 110/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 111/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 112/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 113/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 114/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 115/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 116/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 117/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 118/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 119/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 120/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 121/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 122/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 123/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 124/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 125/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 126/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 127/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 128/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 129/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 130/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 131/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 132/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 133/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 134/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 135/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 136/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 137/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 138/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 139/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 140/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 141/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 142/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 143/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 144/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 145/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 146/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 147/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 148/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 149/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 150/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 151/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 152/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 153/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 154/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 155/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 156/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 157/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 158/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 159/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 160/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 161/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 162/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 163/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 164/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 165/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 166/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 167/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 168/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 169/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 170/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 171/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 172/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 173/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 174/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 175/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 176/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 177/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 178/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 179/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 180/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 181/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 182/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 183/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 184/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 185/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 186/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 187/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 188/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 189/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 190/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 191/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 192/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 193/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 194/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 195/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 196/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 197/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 198/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 199/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 200/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 201/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 202/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 203/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 204/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 205/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 206/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 207/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 208/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 209/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 210/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 211/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 212/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 213/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 214/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 215/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 216/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 217/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 218/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 219/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 220/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 221/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 222/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 223/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 224/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 225/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 226/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 227/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 228/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 229/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 230/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 231/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 232/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 233/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 234/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 235/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 236/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 237/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 238/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 239/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 240/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 241/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 242/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 243/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 244/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 245/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 246/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 247/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 248/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 249/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 250/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 251/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 252/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 253/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 254/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 255/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 256/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 257/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 258/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 259/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 260/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 261/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 262/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 263/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 264/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 265/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 266/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 267/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 268/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 269/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 270/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 271/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 272/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 273/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 274/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 275/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 276/500\n",
      "125/125 [==============================] - 5s 37ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 277/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 278/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 279/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 280/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 281/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 282/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 283/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 284/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 285/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 286/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 287/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 288/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 289/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 290/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 291/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 292/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 293/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 294/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 295/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 296/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 297/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 298/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 299/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 300/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 301/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 302/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 303/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 304/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 305/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 306/500\n",
      "125/125 [==============================] - 5s 36ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 307/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 308/500\n",
      "125/125 [==============================] - 4s 34ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 309/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 310/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 311/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 312/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 313/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 314/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 315/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 316/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 317/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 318/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 319/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 320/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 321/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 322/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 323/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 324/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 325/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 326/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 327/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 328/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 329/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 330/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 331/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 332/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 333/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 334/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 335/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 336/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 337/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 338/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 339/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 340/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 341/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 342/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 343/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 344/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 345/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 346/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 347/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 348/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 349/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 350/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 351/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 352/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 353/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 354/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 355/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 356/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 357/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 358/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 359/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 360/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 361/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 362/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 363/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 364/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 365/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 366/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 367/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 368/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 369/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 370/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 371/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 372/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 373/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 374/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 375/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 376/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 377/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 378/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 379/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 380/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 381/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 382/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 383/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 384/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 385/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 386/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 387/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 388/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 389/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 390/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 391/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 392/500\n",
      "125/125 [==============================] - 4s 34ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 393/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 394/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 395/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 396/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 397/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 398/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 399/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 400/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 401/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 402/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 403/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 404/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 405/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 406/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 407/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 408/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 409/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 410/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 411/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 412/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 413/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 414/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 415/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 416/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 417/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 418/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 419/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 420/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 421/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 422/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 423/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 424/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 425/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 426/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 427/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 428/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 429/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 430/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 431/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 432/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 433/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 434/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 435/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 436/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 437/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 438/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 439/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 440/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 441/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 442/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 443/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 444/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 445/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 446/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 447/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 448/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 449/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 450/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 451/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 452/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 453/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 454/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 455/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 456/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 457/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 458/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 459/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 460/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 461/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 462/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 463/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 464/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 465/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 466/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 467/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 468/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 469/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 470/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 471/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 472/500\n",
      "125/125 [==============================] - 4s 33ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 473/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 474/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 475/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 476/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 477/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 478/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 479/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 480/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 481/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 482/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 483/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 484/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 485/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 486/500\n",
      "125/125 [==============================] - 4s 31ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 487/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 488/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 489/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 490/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 491/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 492/500\n",
      "125/125 [==============================] - 4s 30ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 493/500\n",
      "125/125 [==============================] - 4s 32ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 494/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 495/500\n",
      "125/125 [==============================] - 4s 29ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 496/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 497/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 498/500\n",
      "125/125 [==============================] - 4s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 499/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n",
      "Epoch 500/500\n",
      "125/125 [==============================] - 3s 28ms/step - loss: nan - accuracy: 0.6414 - val_loss: nan - val_accuracy: 0.6382\n"
     ]
    }
   ],
   "source": [
    "# We will now begin training the RNN with the training data we encoded earlier, using the hyperparameters we defined.\n",
    "# To prevent overcorrection or memorization of the data, we will dedicate 20% of the data to validation. We will store\n",
    "# the results of the training session for later analysis.\n",
    "RNN_results = RNN.fit(X_train,\n",
    "                      y_train,\n",
    "                      epochs=KERAS_EPOCHS,\n",
    "                      batch_size=KERAS_BATCHES,\n",
    "                      verbose=1,\n",
    "                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now import the model made with Core ML to evaluate it.\n",
    "import coremltools as ct\n",
    "\n",
    "# Load the ML model from the pre-compiled models folder. At this time, we cannot determine the initial training session\n",
    "# data because it's not included in the model file. We can, however, test the testing data later.\n",
    "CORE_ML = ct.models.MLModel('../coreml/apple_var.mlmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Evaluation of Networks\n",
    "\n",
    "Now that the models have been trained, we will use the testing set to test their accuracy scores and see how they fare\n",
    "against each other. We will later investigate with a different test that will remove words from a test dictionary.\n",
    "\n",
    "To accomplish this task, we will run evaulation functions on each of the models and compare their graphs and scores\n",
    "accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating FCNN\n",
      "622/622 [==============================] - 2s 3ms/step - loss: 0.3953 - accuracy: 0.8221\n",
      "Evaluating RNN\n",
      "622/622 [==============================] - 3s 5ms/step - loss: nan - accuracy: 0.6428\n",
      "Evaluating CoreML\n",
      "loss: 0.0784658691062632 - accuracy: 0.9215341308937368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluate the FCNN with the testing dataset.\n",
    "print(\"Evaluating FCNN\")\n",
    "evaluation_FCNN = FCNN.evaluate(X_test, y_test, verbose=1)\n",
    "y_predict_fcnn = FCNN.predict(X_test)\n",
    "\n",
    "# Evaluate the RNN with the testing dataset.\n",
    "print(\"Evaluating RNN\")\n",
    "evaluation_RNN = RNN.evaluate(X_test, y_test, verbose=1)\n",
    "y_predict_rnn = RNN.predict(X_test)\n",
    "\n",
    "# Evaluate the CoreML model with the testing dataset. We will need to do this manually, since the CoreML evaluators do\n",
    "# NOT provide accuracy or loss metrics.\n",
    "print(\"Evaluating CoreML\")\n",
    "DF_REFORMATTED_TESTING_POOL = DF_TESTING_POOL.drop(\"Valid\", axis=1).to_dict(orient='records')\n",
    "y_true = [1 if i == \"valid\" else 0 for i in list(DF_TESTING_POOL['Valid'])]\n",
    "predictions = [CORE_ML.predict(row)['Valid'] for row in DF_REFORMATTED_TESTING_POOL]\n",
    "y_predict_coreml = [1 if i == \"valid\" else 0 for i in predictions]\n",
    "eval_loss = brier_score_loss(y_true, y_predict_coreml)\n",
    "eval_accuracy = accuracy_score(y_true, y_predict_coreml)\n",
    "\n",
    "evaluation_CORE_ML = [eval_loss, eval_accuracy]\n",
    "print(f\"loss: {eval_loss} - accuracy: {eval_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNN Stats: 82.21% accuracy, 39.53% loss\n",
      "RNN Stats: 64.28% accuracy, nan% loss\n",
      "Apple CoreML Stats: 92.15% accuracy, 7.85% loss\n"
     ]
    }
   ],
   "source": [
    "# To compare the networks, we will use a confusion matrix, which displays the distribution of correct and incorrect\n",
    "# predictions. The format is as follows:\n",
    "#\n",
    "# [[ True Negatives     False Positives\n",
    "#    False Negatives    True Positives ]]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Map the predictions of the FCNN and the RNN to be binary so as to match the true format.\n",
    "force_validity = np.vectorize(lambda a: 1 if a > 0.5 else 0)\n",
    "y_predict_fcnn = force_validity(y_predict_fcnn)\n",
    "y_predict_rnn = force_validity(y_predict_rnn)\n",
    "\n",
    "figure, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(16, 4)) # type: ignore\n",
    "\n",
    "# Generate the confusion matrix for the FCNN predictions and display it.\n",
    "cm_fcnn = confusion_matrix(y_true, y_predict_fcnn)\n",
    "ConfusionMatrixDisplay(cm_fcnn).plot(ax=ax1)\n",
    "ax1.set_title(\"Fully-connected Neural Network (FCNN)\")\n",
    "\n",
    "# Generate the confusion matrix for the RNN and display it.\n",
    "cm_rnn = confusion_matrix(y_true, y_predict_rnn)\n",
    "ConfusionMatrixDisplay(cm_rnn).plot(ax=ax2)\n",
    "ax2.set_title(\"Recurrent Neural Network (RNN)\")\n",
    "\n",
    "# Generate the confusion matrix for the Apple CoreML model and display it.\n",
    "cm_coreml = confusion_matrix(y_true, y_predict_coreml)\n",
    "ConfusionMatrixDisplay(cm_coreml).plot(ax=ax3)\n",
    "ax3.set_title(\"Apple CoreML Model\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"FCNN Stats: %.2f%% accuracy, %.2f%% loss\" % (evaluation_FCNN[1] * 100, evaluation_FCNN[0] * 100))\n",
    "print(\"RNN Stats: %.2f%% accuracy, %.2f%% loss\" % (evaluation_RNN[1] * 100, evaluation_RNN[0] * 100))\n",
    "print(\"Apple CoreML Stats: %.2f%% accuracy, %.2f%% loss\" % (evaluation_CORE_ML[1] * 100, evaluation_CORE_ML[0] * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae728774eee256562aff2651c76309c3916f29437b55f618701e1f4834ebef1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env_tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
