{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Abysima: Generating a Language with Machine Learning\n",
    "\n",
    "The following notebook will experiment with generating a language using neural networks and generative deep learning.\n",
    "This is, by no means, a production-ready system, nor is it a complete network; rather, the purpose of this experiment\n",
    "is to see what is possible with creating a language.\n",
    "\n",
    "For more information on the process and supporting research, please refer to the Linguistics Paper document found in the\n",
    "`01 - Areas of Responsibility` directory.\n",
    "\n",
    "The following source code and datasets are licensed under the Mozilla Public License v2.0. Please refer to the LICENSE\n",
    "file that came with this repository for more information on what your rights are with usage and modification of this\n",
    "software. If a LICENSE file is not provided, you can obtain a copy at https://www.mozilla.org/en-US/MPL/2.0/.\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Initial Setup\n",
    "\n",
    "We'll need to write some utilities and codes that will allow us to generate, predict, and validate words. This\n",
    "section will allow us to do just that.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Unix-based and Unix-like systems have a file on the computer that contains a list of words used for spell-checking.\n",
    "# This file is located in /usr/share/dict/words and contains various parts of speech, including proper nouns. For the\n",
    "# purposes of this experiment, a copy provided from an installation of Pop!_OS 20.04 LTS (based on Ubuntu) will be used.\n",
    "# If that file cannot be located, the file located on the system will be used instead.\n",
    "import os\n",
    "\n",
    "\n",
    "def is_admissible(word: str) -> bool:\n",
    "    \"\"\"Returns whether a word is considered admissible for the dataset.\n",
    "    \n",
    "    For the purposes of the dataset, a word is admissible if it conforms to the following:\n",
    "    - The word only contains ASCII characters; i.e., the word does not have any accents.\n",
    "    - The word only contains letters in the alphabet\n",
    "    - The word is not a proper noun or acronym (i.e., the word doesn't have uppercase letters)\n",
    "    - The word is not a contraction.\n",
    "    \"\"\"\n",
    "    real_word = word.strip()\n",
    "    return real_word.isascii() and real_word.isalpha() and real_word.islower(\n",
    "    ) and not real_word.endswith(\"'s\")\n",
    "\n",
    "\n",
    "# Open the words file and grab all of the admissible words.\n",
    "WORDS_FILE = \"outside_sources/words\" if os.path.isfile(\n",
    "    \"outside_sources/words\") else \"/usr/share/dict/words\"\n",
    "with open(WORDS_FILE, 'r') as words:\n",
    "    valid_words = [\n",
    "        w.strip().lower() for w in words.readlines() if is_admissible(w)\n",
    "    ]\n",
    "print(f\"Number of admissible words from {WORDS_FILE}: {len(valid_words)}\")\n",
    "\n",
    "# Open the converted dataset from the Wiktionary page and import that into the list of valid words.\n",
    "with open(\"outside_sources/jp-romaji.txt\") as jp_data:\n",
    "    valid_words += [w.strip().lower() for w in jp_data.readlines()]\n",
    "\n",
    "print(f\"Number of total words including Japanese words: {len(valid_words)}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of admissible words from outside_sources/words: 63248\n",
      "Number of total words including Japanese words: 63863\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Create a bunch of nonsencial words that are not valid.\n",
    "from random import randrange\n",
    "from string import ascii_lowercase\n",
    "\n",
    "\n",
    "def random_string() -> str:\n",
    "    \"\"\"Returns a string of a random length between 3 and 12 characters, with no syllabic structure in mind.\"\"\"\n",
    "    length = randrange(3, 12)\n",
    "    string = \"\"\n",
    "    for _ in range(length):\n",
    "        next_index = randrange(0, len(ascii_lowercase) - 1)\n",
    "        string += ascii_lowercase[next_index]\n",
    "    return string\n",
    "\n",
    "\n",
    "invalid = [random_string() for _ in range(len(valid_words))]\n",
    "print(invalid[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['wqqtfb', 'ffe', 'pjtnkg', 'tnutuixpv', 'aaw', 'brghj', 'twmck', 'yullhymu', 'nwdmgrt', 'viplhgb']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# Grab the contents of the test dictionary, which contains completely randomly-generated words from the random word\n",
    "# generator defined in random_strings. These words follow common syllabic structures and will be filtered according to\n",
    "# what the network defines as a valid word later.\n",
    "\n",
    "with open(\"test_dict.txt\", \"r\") as dict_file:\n",
    "    test_dict = [word.strip() for word in dict_file.readlines()]\n",
    "\n",
    "print(test_dict[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['xewetov', 'rskyesphbdj', 'wudnanvo', 'does', 'doowkguy', 'qtasvymmeq', 'hihebuxa', 'kftealnlhnp', 'gevhenly', 'deacgiecj']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Assemble the dataset with the valid and invalid words. Words that are valid will be marked as 1 for its output,\n",
    "# and words that are not valid are marked as 0 for its output.\n",
    "from string import ascii_lowercase\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def map_word(word: str) -> list:\n",
    "    \"\"\"Returns a list of numbers from 1 to 26 that represent the various letters in the alphabet.\"\"\"\n",
    "    get_idx = lambda i: ascii_lowercase.index(i) + 1\n",
    "    return [get_idx(c) for c in word]\n",
    "\n",
    "\n",
    "# Fill any shorter words with the maximum length of the words. For words shorter than the word with the most\n",
    "# characters, a 0 will be subsistuted to keep the length of features consistent.\n",
    "def fill_word_features(word: list, fill_length: int) -> list:\n",
    "    if len(word) >= fill_length:\n",
    "        return word\n",
    "    diff = fill_length - len(word)\n",
    "    return [0 for i in range(diff)] + word\n",
    "\n",
    "\n",
    "# Get the length of the longest word in the valid words dataset.\n",
    "max_len = max([len(str(w)) for w in valid_words])\n",
    "print(f\"Longest word length: {max_len}\")\n",
    "\n",
    "# Encode the data set into a format that the neural network will be able to understand.\n",
    "encoded_correct = [map_word(str(word)) for word in valid_words]\n",
    "# encoded_correct = []\n",
    "# for word in valid_words:\n",
    "#     print(word)\n",
    "#     encoded_correct.append(map_word(word))\n",
    "encoded_correct = [fill_word_features(w, max_len) for w in encoded_correct]\n",
    "\n",
    "encoded_invalid = [map_word(str(word)) for word in invalid]\n",
    "encoded_invalid = [fill_word_features(w, max_len) for w in encoded_invalid]\n",
    "\n",
    "# Map the values with their corresponding outputs.\n",
    "mapped_correct = [word + [1] for word in encoded_correct]\n",
    "mapped_invalid = [word + [0] for word in encoded_invalid]\n",
    "\n",
    "dataset = mapped_correct + mapped_invalid\n",
    "\n",
    "# Shuffle the dataset around.\n",
    "from random import shuffle\n",
    "for _ in range(20):\n",
    "    shuffle(dataset)\n",
    "\n",
    "# Cast the dataset to a numpy array, and split the features from the expected output.\n",
    "dataset = np.array(dataset)\n",
    "X = dataset[:, :-1]\n",
    "Y = dataset[:, -1]\n",
    "\n",
    "# Divide values by 26 (the number of letters in the alphabet). Doing this will make sure our data remains consistent,\n",
    "# and that we are not stating that Z is 26 times more important and A. This process is known as normalization.\n",
    "X = X / 26\n",
    "\n",
    "# Print the first two entries in the dataset as an example.\n",
    "print(X[:2])\n",
    "print(Y[:2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Longest word length: 22\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.61538462 0.96153846 0.84615385 0.57692308 0.34615385\n",
      "  0.61538462 0.5        0.69230769 0.5       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.03846154 0.23076923\n",
      "  0.76923077 0.19230769 0.61538462 0.53846154]]\n",
      "[0 0]\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Splitting Models for Validation and Testing\n",
    "\n",
    "In order to prevent the neural network we will generate from overcorrecting itself or memorizing the data we give\n",
    "it, we will create three different sets of the dataset: a training set, a validation set, and a testing set. The\n",
    "training set will be used to train the model, and the model will use the validation set occasionally to validate\n",
    "that it isn't overfitting. We will then use the testing set to test out the model and see what comes out of it.\n",
    "\n",
    "To accomplish this, we will use a 60% training/20% validation/20% testing split for the datasets.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Split the data in training and testing data. When we fit the model, we can specify a validation set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3: Creating The Predictive Model\n",
    "\n",
    "Now that we have a dataset, we will create the neural network model with Keras and fit it using the training data.\n",
    "This will also use a small portion of that data for validation purposes.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Start by creating the model.\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "model = keras.Sequential(name=\"Abysima_2\")\n",
    "model.add(Dense(max_len, input_dim=max_len, activation='relu'))\n",
    "model.add(Dense(max_len * 4, activation='relu'))\n",
    "# model.add(Dense(max_len/4, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# Create an early stopping mechanism to stop early if accuracy isn't improving after a certain point. This prevents\n",
    "# unnecessary computations.\n",
    "stop_early = EarlyStopping(monitor='accuracy', patience=7)\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.6.0\n",
      "Model: \"Abysima_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 22)                506       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 88)                2024      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 89        \n",
      "=================================================================\n",
      "Total params: 2,619\n",
      "Trainable params: 2,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Fit the model to our dataset. In this instance, the model will run a batch gradient descent learning algorithm\n",
    "# for 100 epochs with a determined batch size. Additionally, it will set aside 20% of the data for validation.\n",
    "training_results = model.fit(X_train,\n",
    "                             y_train,\n",
    "                             epochs=100,\n",
    "                             batch_size=128,\n",
    "                             verbose=1,\n",
    "                             validation_split=0.2,\n",
    "                             callbacks=[stop_early])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      " 17/639 [..............................] - ETA: 4s - loss: 0.0000e+00 - accuracy: 0.5074"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-19 21:05:10.875285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "636/639 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.4995"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-19 21:05:14.755563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "639/639 [==============================] - 5s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 2/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 3/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 4/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 5/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 6/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 7/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n",
      "Epoch 8/100\n",
      "639/639 [==============================] - 4s 7ms/step - loss: 0.0000e+00 - accuracy: 0.4995 - val_loss: 0.0000e+00 - val_accuracy: 0.5025\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Plot the accuracy and loss changes for comparison. If we see an overlap, there may be overfitting involved.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(training_results.history['accuracy'],\n",
    "         label='Accuracy over iterations')\n",
    "plt.plot(training_results.history['loss'], label='Loss over iterations')\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16ab2ddf0>"
      ]
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "plt.plot(training_results.history['val_accuracy'],\n",
    "         label='Validation accuracy over iterations')\n",
    "plt.plot(training_results.history['val_loss'],\n",
    "         label='Validation loss over iterations')\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15f5a4dc0>"
      ]
     },
     "metadata": {},
     "execution_count": 104
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Testing with the Testing Set\n",
    "\n",
    "Now that the model is trained, we will use the testing set to test the results of the model's fitting process.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# Predict the testing data.\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "def unmap_word(word: list) -> str:\n",
    "    \"\"\"Returns a string from a list of numbers from 0 to 1 that represent the different letters of the alphabet.\n",
    "    \n",
    "    For numbers less than or equal to zero, they are skipped since they are not valid entries.\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    for num in word:\n",
    "        if num < 1:\n",
    "            continue\n",
    "        result = result + ascii_lowercase[int(num) - 1]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Go through each of the predictions and store the number of predictions it got correct, and capture any failed\n",
    "# predictions for inspection.\n",
    "number_correct = 0\n",
    "errors = []\n",
    "for idx, prediction in enumerate(test_predictions):\n",
    "    actual = y_test[idx]\n",
    "    if prediction == actual:\n",
    "        number_correct += 1\n",
    "    else:\n",
    "        errors.append((idx, prediction, actual))\n",
    "\n",
    "# Calculate the accuracy percentage.\n",
    "accuracy_percentage = (number_correct / len(y_test)) * 100\n",
    "print(f\"Percent correct: {accuracy_percentage:02f}%\")\n",
    "print(f\"Number of incorrect predictions: {len(y_test) - number_correct}\")\n",
    "\n",
    "# Print the first five of the incorrect predictions.\n",
    "print(\"===Incorrect Predictions===\")\n",
    "for idx, pred, act in errors[:5]:\n",
    "    word = unmap_word(X_test[idx] * 26)\n",
    "    pred_str = \"valid\" if pred else \"invalid\"\n",
    "    act_str = \"valid\" if act else \"invalid\"\n",
    "    print(\n",
    "        f\"Prediction was {pred_str},\\t where actual was {act_str}\\t\\tWord: {word}\"\n",
    "    )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-19 21:05:45.238402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percent correct: 49.949111%\n",
      "Number of incorrect predictions: 12786\n",
      "===Incorrect Predictions===\n",
      "Prediction was valid,\t where actual was invalid\t\tWord: wfteh\n",
      "Prediction was valid,\t where actual was invalid\t\tWord: fnqsnnuks\n",
      "Prediction was valid,\t where actual was invalid\t\tWord: tcgvf\n",
      "Prediction was valid,\t where actual was invalid\t\tWord: ttgnxr\n",
      "Prediction was valid,\t where actual was invalid\t\tWord: rymdbju\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 5: Filtering Out \"Invalid\" Words in the Test Dictionary\n",
    "\n",
    "Now that we have model that seems to be reasonably accurate, we can use our test dictionary to filter out words\n",
    "that the network considers invalid.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# Encode the test_dict the same way we encoded the dataset.\n",
    "encoded_test = [map_word(w) for w in test_dict]\n",
    "encoded_test = [fill_word_features(w, max_len) for w in encoded_test]\n",
    "\n",
    "# Make predictions of the test_dict and collect all of the words it considered valid.\n",
    "dict_predictions = model.predict(encoded_test)\n",
    "valid_dictionary = []\n",
    "for idx, prediction in enumerate(dict_predictions):\n",
    "    if prediction == 0:\n",
    "        continue\n",
    "    valid_dictionary.append(test_dict[idx])\n",
    "\n",
    "# Print some of the valid words, as well as how big the list actually is.\n",
    "trim_count = len(test_dict) - len(valid_dictionary)\n",
    "print(\n",
    "    f\"Trimmed {trim_count} invalid words from the test dictionary (now size {len(test_dict)}).\"\n",
    ")\n",
    "print(valid_dictionary[:10])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trimmed 0 invalid words from the test dictionary (now size 500).\n",
      "['xewetov', 'rskyesphbdj', 'wudnanvo', 'does', 'doowkguy', 'qtasvymmeq', 'hihebuxa', 'kftealnlhnp', 'gevhenly', 'deacgiecj']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-19 21:05:45.974969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2525e10832b7ba92743f6be5b80dfb53422b22d81bf31403f095ad9684056cbf"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('env_tensorflow': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}