{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Abysima: Generating a Language with Machine Learning\n",
    "\n",
    "The following notebook will experiment with generating a language using neural networks and generative deep learning.\n",
    "This is, by no means, a production-ready system, nor is it a complete network; rather, the purpose of this experiment\n",
    "is to see what is possible with creating a language.\n",
    "\n",
    "For more information on the process and supporting research, please refer to the Linguistics Paper document found in the\n",
    "`01 - Areas of Responsibility` directory.\n",
    "\n",
    "The following source code and datasets are licensed under the Mozilla Public License v2.0. Please refer to the LICENSE\n",
    "file that came with this repository for more information on what your rights are with usage and modification of this\n",
    "software. If a LICENSE file is not provided, you can obtain a copy at https://www.mozilla.org/en-US/MPL/2.0/."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part I: Initial Setup\n",
    "\n",
    "This notebook will utilize the TensorFlow and Keras libraries to create the generative neural networks for this project,\n",
    "as well as some other Python libraries to parse the data from CSV files or other file formats."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import the Keras packages we will use to create the neural network models, and to parse the dataset.\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import pandas to be able to read the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "# Import typing hints to make code readable.\n",
    "from typing import List"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part II: Dataset Parsing and Encoding\n",
    "\n",
    "Before the dataset can be thrown into the neural network, we first need to sanitize and prepare the dataset for use with\n",
    "the network. This will also include creating training, validation, and testing sets to ensure accuracy while mitigating\n",
    "overfitting.\n",
    "\n",
    "### Differentiating Sounds and the Use of IPA Symbols\n",
    "\n",
    "Given that different languages have different writing systems, and correlation between characters and sounds may be\n",
    "difficult to extrapolate, we will assume that all strings in this network will be written using the International\n",
    "Phonetic Alphabet (IPA). IPA symbols correspond to a particular sound and can be classified by different features with\n",
    "respect to how the sound is made.\n",
    "\n",
    "Note that not all languages use every symbol available in IPA. For instance, English does not use [Ɣ]."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Create a blank mapping for the IPA symbols. This will be used to map various IPA symbols to numbers\n",
    "# that the neural network can use, rather than Unicode characters.\n",
    "IPA_SYMBOLS = {}\n",
    "\n",
    "# Open the IPA symbols mapping file in Pandas to read the data as a CSV file data frame, and verify\n",
    "# the names and features are correct in the file.\n",
    "ipa_symbols_file = pd.read_csv(\"ipasymbs.csv\")\n",
    "print(ipa_symbols_file.head(8))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  IPA  Feature\n",
      "0   p        1\n",
      "1   t        2\n",
      "2   k        3\n",
      "3   ʔ        4\n",
      "4   b        5\n",
      "5   d        6\n",
      "6   g        7\n",
      "7   m        8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Iterate through every row in the list and add the mapping from IPA symbol to feature.\n",
    "for _, row in ipa_symbols_file.iterrows():\n",
    "    IPA_SYMBOLS[row['IPA']] = row['Feature']\n",
    "\n",
    "print(IPA_SYMBOLS.keys())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['p', 't', 'k', 'ʔ', 'b', 'd', 'g', 'm', 'n', 'ɲ', 'ŋ', 'ɸ', 'f', 'θ', 's', 'ʃ', 'ç', 'x', 'ħ', 'h', 'ẞ', 'v', 'ð', 'z', 'Ʒ', 'Ɣ', 'ʁ', 'ʕ', 'ts', 'tʃ', 'ʣ', 'ʤ', 'w', 'ɹ', 'j', 'l', 'r', 'ɾ', 'i', 'ü', 'ɨ', 'ɯ', 'u', 'ɪ', 'ʊ', 'e', 'ə', 'o', 'ɛ', 'ʌ', 'ɔ', 'æ', 'a', 'ɑ'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Verify we can map IPA symbols to integers by passing in an IPA string and replacing the characters\n",
    "# with feature integers.\n",
    "# \n",
    "# Example: <shout> [ʃaʊt] -> [16, 53, 45, 2]\n",
    "class IPAString(str):\n",
    "    \"\"\"A subclass of string in which the characters are IPA symbols that correspond to features.\"\"\"\n",
    "    def __str__(self):\n",
    "        res = str.__repr__(self).replace(\"''\", \"\")\n",
    "        return f\"[{res}]\"\n",
    "    def to_features(self) -> List[int]:\n",
    "        return [IPA_SYMBOLS[c] for c in self]\n",
    "\n",
    "shout_features = IPAString(\"ʃaʊt\").to_features()\n",
    "print(shout_features)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16, 53, 45, 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Rules for phonemes will be defined as the following format, stored in a .rules file:\n",
    "#    [ʃa] -> [ʊ]\n",
    "#    [ʃa] -> [i]\n",
    "#\n",
    "# This will need to be parsed and converted into a matrix that the network can use. To do this\n",
    "# some functions have been written in another file.\n",
    "from phoneme_rules import read_rules_as_rows\n",
    "\n",
    "# To demonstrate and verify the file is read correctly, a sample file will be parsed. The result\n",
    "# should be a two-dimensional array that includes the left side of the rules as inputs, and the\n",
    "# right side of the rules as outputs.\n",
    "sample_data = read_rules_as_rows(\"sample.rules\")\n",
    "\n",
    "# Split the data into its inputs and outputs.\n",
    "inputs = []\n",
    "outputs = []\n",
    "for row in sample_data:\n",
    "    inputs.append(row[:-1])\n",
    "    outputs.append(row[len(row) - 1])\n",
    "print(inputs, outputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['ʃ', 'a'], ['ʃ', 'a']] ['Ʊ', 'i']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}