{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Abysima: Generating a Language with Machine Learning\n",
    "\n",
    "The following notebook will experiment with generating a language using neural networks and generative deep learning.\n",
    "This is, by no means, a production-ready system, nor is it a complete network; rather, the purpose of this experiment\n",
    "is to see what is possible with creating a language.\n",
    "\n",
    "For more information on the process and supporting research, please refer to the Linguistics Paper document found in the\n",
    "`01 - Areas of Responsibility` directory.\n",
    "\n",
    "The following source code and datasets are licensed under the Mozilla Public License v2.0. Please refer to the LICENSE\n",
    "file that came with this repository for more information on what your rights are with usage and modification of this\n",
    "software. If a LICENSE file is not provided, you can obtain a copy at https://www.mozilla.org/en-US/MPL/2.0/."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part I: Initial Setup\n",
    "\n",
    "This notebook will utilize the TensorFlow and Keras libraries to create the generative neural networks for this project,\n",
    "as well as some other Python libraries to parse the data from CSV files or other file formats."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import the Keras packages we will use to create the neural network models, and to parse the dataset.\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part II: Dataset Parsing and Encoding\n",
    "\n",
    "Before the dataset can be thrown into the neural network, we first need to sanitize and prepare the dataset for use with\n",
    "the network. This will also include creating training, validation, and testing sets to ensure accuracy while mitigating\n",
    "overfitting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Implement this code block"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}